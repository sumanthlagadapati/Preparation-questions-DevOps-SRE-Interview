# L1 — Basics & Scenarios

### 1) Briefly introduce yourself

I’m a DevOps/SRE engineer with \~9–10 years across AWS, Kubernetes, Terraform, and CI/CD (Jenkins/GitLab). 
I build IaC with Terraform, automate delivery with pipelines, ship containers to EKS with Helm/GitOps, and harden systems with secrets management, image scanning, and observability (Prometheus/Grafana/Datadog). I focus on reducing MTTR, predictable releases, and cost/perf optimizations.

---

### 2) How do you securely authenticate your cloud with Terraform?

* **Local dev:** `aws configure` or `AWS_PROFILE`, short-lived STS via MFA/`aws sso login`.
* **CI/CD:** **OIDC federation** (e.g., GitHub Actions ↔ IAM role with trust policy), no static keys.
* **Least privilege:** dedicated IAM roles/policies per workspace/env.
* **No keys in code**; rely on provider assuming role:

  ```hcl
  provider "aws" {
    region  = var.region
    assume_role { role_arn = var.deployment_role_arn }
  }
  ```

---

### 3) How do you store secrets in Terraform?

* **Don’t** hardcode. Use:

  * **AWS Secrets Manager / SSM Parameter Store** via data sources.
  * **Vault provider** for dynamic creds.
  * `variable "x" { sensitive = true }` and pass via `TF_VAR_x` or CI secrets.
* Example:

  ```hcl
  data "aws_secretsmanager_secret_version" "db" {
    secret_id = "prod/db_password"
  }

  variable "db_user" { type = string }
  output "db_password" {
    value     = jsondecode(data.aws_secretsmanager_secret_version.db.secret_string).password
    sensitive = true
  }
  ```

---

### 4) What is a backend in Terraform? Why use it?

A **backend** stores **state** remotely (S3, GCS, Azure Blob, Terraform Cloud) and enables **locking**, **collaboration**, **encryption**, and **versioning**.

```hcl
terraform {
  backend "s3" {
    bucket         = "prod-tf-state"
    key            = "net/vpc.tfstate"
    region         = "us-east-1"
    dynamodb_table = "tf-locks"
    encrypt        = true
  }
}
```

---

### 5) If you have existing infrastructure, how do you replicate it into Terraform state?

1. Write matching resource blocks.
2. **Import** each resource:

```bash
terraform import aws_instance.web i-0123456789abcdef0
```

3. `terraform plan` to reconcile.
   Tip: Tools like **Terraformer** can generate HCL from existing resources (review carefully).

---

### 6) Lost the `.pem` key — how can you connect to your server?

* **SSM Session Manager** (if SSM agent/role is present) — no SSH keys needed.
* **EC2 Instance Connect** (supported AMIs).
* **Attach volume** to a helper instance, edit `~/.ssh/authorized_keys`, reattach.
* **User data** on next boot to inject a new key.
* **Bastion** (if already configured) with authorized users.

---

### 7) CI/CD: artifacts in one S3 bucket, deploy to another S3 in a **different AWS account** — how to connect?

* Use **cross-account IAM role** in target account; grant `s3:*` on target bucket.
* CI role **assumes** that role via STS:

  * Target account bucket policy allows the role.
  * Source account pipeline role has `sts:AssumeRole` to target.
* In pipeline:

```bash
aws sts assume-role --role-arn arn:aws:iam::<TARGET>:role/deployRole ...
AWS_ACCESS_KEY_ID=... AWS_SECRET_ACCESS_KEY=... aws s3 sync build s3://target-bucket/
```

---

### 8) What is VPC Peering and Transit Gateway?

* **VPC Peering:** 1:1 private routing between two VPCs (no transitive routing).
* **Transit Gateway (TGW):** hub-and-spoke for **many-to-many** VPC/VPN/DirectConnect with centralized routing and transitivity. Use TGW at scale/multi-region.

---

### 9) Common CloudFront issues you’ve faced

* **SSL cert in us-east-1** requirement (for custom domains).
* **403/404** due to OAC/OAI or bucket policies.
* **CORS** misconfig.
* **Long invalidation times** / cache behavior mismatches.
* **Origin timeouts** or bad health checks.

---

### 10) Types of AWS Load Balancers & when to use them

* **ALB (L7 HTTP/HTTPS):** microservices, path/host routing, WebSockets, sticky sessions.
* **NLB (L4 TCP/UDP):** high throughput/low latency, static IPs, TLS passthrough.
* **CLB (classic):** legacy; avoid for new builds.

---

### 11) Docker `CMD` vs `ENTRYPOINT`

* **ENTRYPOINT** = main executable (hard to override).
* **CMD** = default args (or default command if ENTRYPOINT absent).
  Combine:

```dockerfile
ENTRYPOINT ["node","server.js"]
CMD ["--port","3000"]
```

---

### 12) Basic Dockerfile for Node.js

```dockerfile
FROM node:20-alpine
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY . .
EXPOSE 3000
CMD ["node","server.js"]
```

---

### 13) Deployment vs StatefulSet (Kubernetes)

* **Deployment:** stateless, interchangeable pods, no strict identity.
* **StatefulSet:** stable identities (`pod-0`…), stable storage (PVC per pod), ordered ops — use for DBs/brokers.

---

# L2 — Hands-On & Advanced

### 1) Jenkins Declarative Pipeline with `post`

```groovy
pipeline {
  agent { label 'linux-docker' }

  options { timestamps(); ansiColor('xterm') }

  stages {
    stage('Checkout') {
      steps { checkout scm }
    }
    stage('Build') {
      steps { sh 'mvn -B -DskipTests package' }
    }
    stage('Unit Tests') {
      steps { sh 'mvn test' }
    }
    stage('Build & Push Image') {
      steps {
        sh '''
          docker build -t $ECR_REPO:$GIT_COMMIT .
          docker push $ECR_REPO:$GIT_COMMIT
        '''
      }
    }
    stage('Deploy') {
      steps { sh 'helm upgrade --install api charts/api -f values/prod.yaml --set image.tag=$GIT_COMMIT' }
    }
  }

  post {
    success { echo '✅ Pipeline succeeded'; sh 'curl -X POST $SLACK_OK' }
    failure { echo '❌ Pipeline failed';     sh 'curl -X POST $SLACK_FAIL' }
    always  { archiveArtifacts artifacts: 'target/*.jar', fingerprint: true }
  }
}
```

---

### 2) COPY vs ADD in Docker

* **COPY**: copy local files.
* **ADD**: also supports **remote URLs** and **auto-extracts** local tar files.
  Best practice: **prefer COPY**; use ADD only when you need those extras.

---

### 3) Multistage Dockerfile vs Distroless

* **Multistage:** build in one stage, copy only artifacts to a tiny runtime → smaller, cleaner images.
* **Distroless:** runtime image contains **only your app + minimal libs** (no shell/package manager) → very small and more secure. Often used **together** (multistage build → distroless run).

---

### 4) Multistage Dockerfile for Node.js

```dockerfile
# --- Build stage ---
FROM node:20-alpine AS build
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

# --- Runtime stage (distroless optional alternative below) ---
FROM node:20-alpine
WORKDIR /app
ENV NODE_ENV=production
COPY --from=build /app/package*.json ./
RUN npm ci --omit=dev
COPY --from=build /app/dist ./dist
EXPOSE 3000
CMD ["node","dist/server.js"]

# Distroless runtime (swap the runtime stage above):
# FROM gcr.io/distroless/nodejs20
# WORKDIR /app
# COPY --from=build /app/dist ./dist
# COPY --from=build /app/package*.json ./
# ENV NODE_ENV=production
# EXPOSE 3000
# CMD ["dist/server.js"]
```

---

### 5) Explain Kubernetes Architecture (how it works)

* **Control Plane (masters):**

  * **API Server** (front door), **etcd** (state store), **Scheduler** (where pods go), **Controller Manager** (desired state loops).
* **Worker Nodes:**

  * **kubelet** (talks to API, starts pods), **kube-proxy** (service VIPs), **CNI plugin** (pod networking).
* **Reconciliation:** you declare desired state (YAML). Controllers reconcile until actual == desired.

---

### 6) How to check Jenkins version

* In UI footer or **Manage Jenkins → System Information**.
* CLI / container:

  ```bash
  jenkins --version
  # or
  curl -sI http://<jenkins>/ | grep -i x-jenkins
  ```

---

### 7) Kubernetes Deployment YAML (basic)

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web
  labels: { app: web }
spec:
  replicas: 3
  selector:
    matchLabels: { app: web }
  template:
    metadata:
      labels: { app: web }
    spec:
      containers:
        - name: web
          image: nginx:stable
          ports:
            - containerPort: 80
          resources:
            requests: { cpu: "100m", memory: "128Mi" }
            limits:   { cpu: "500m", memory: "256Mi" }
---
apiVersion: v1
kind: Service
metadata:
  name: web
spec:
  selector: { app: web }
  ports: [{ port: 80, targetPort: 80 }]
  type: ClusterIP
```

---

### 8) Shell script to create an S3 bucket

```bash
#!/usr/bin/env bash
set -euo pipefail

REGION="${1:-us-east-1}"
BUCKET="${2:-my-unique-bucket-$RANDOM}"

echo "Creating bucket: $BUCKET in $REGION"

if aws s3api head-bucket --bucket "$BUCKET" 2>/dev/null; then
  echo "Bucket already exists or you don't own it"; exit 1
fi

if [ "$REGION" = "us-east-1" ]; then
  aws s3api create-bucket --bucket "$BUCKET"
else
  aws s3api create-bucket --bucket "$BUCKET" \
    --create-bucket-configuration LocationConstraint="$REGION" \
    --region "$REGION"
fi

aws s3api put-bucket-versioning --bucket "$BUCKET" --versioning-configuration Status=Enabled
aws s3api put-bucket-encryption --bucket "$BUCKET" --server-side-encryption-configuration '{
  "Rules": [{"ApplyServerSideEncryptionByDefault": {"SSEAlgorithm": "AES256"}}]
}'

echo "✅ Bucket $BUCKET created with versioning + encryption."
```

---
Perfect—here’s a tight, senior-level playbook you can use verbatim in interviews.

# Round 1 – Core Infra, K8s & Cloud Reliability

### 1) CI/CD to safely push updates to **1,000+ GPU nodes** (no downtime)

* **Progressive rings:** `canary (1–2%) → wave-1 (10%) → wave-2 (30%) → global`. Gates between waves (health SLOs, error budgets, GPU job completion rate).
* **NodePool partitioning:** multiple **node groups** per AZ (e.g., `gpu-canary`, `gpu-batch`, `gpu-train`). Update one pool at a time.
* **Workload-aware drain:** `kubectl cordon && kubectl drain --ignore-daemonsets --grace-period=<long>` + **PDBs** + **priority classes** so system DaemonSets (Nvidia drivers, DCGM, Node Exporter) never evict.
* **MaxUnavailable & surge:** for MNG/ASG use small `maxUnavailable` (1–2) per group; **create\_before\_destroy** on LT/AMI; respect **soak times**.
* **GitOps + policy guardrails:** ArgoCD/Flux with **manual hold points**, OPA/Gatekeeper to block risky changes (e.g., removing tolerations from GPU pods).
* **Health gates:** DCGM metrics (SM util, ECC errors), job queue depth, pod pending > N sec, node readiness, NCCL all-reduce time—must pass before the next wave.
* **Rollback plan:** immutable AMIs/Container images; `instance_refresh cancel` + scale back to previous template; Helm `rollback <rev>`.

---

### 2) Enforce **secrets management** across **multi-region GPU clusters** (no hardcoding)

* **Central secrets authority:** HashiCorp Vault or cloud KMS secrets (AWS Secrets Manager/SSM). **Cross-region replication** enabled.
* **Workload Identity:** IRSA (EKS) / Workload Identity (GKE) → Pods assume roles; **no static keys** in images or env.
* **External Secrets Operator:** syncs secrets to K8s (as `Secret`) from Vault/Secrets Manager; encrypt at rest with KMS; short TTL.
* **Sidecar/agent injectors:** Vault Agent templates for on-the-fly cert/secret renewal; rotate DB/user creds automatically.
* **Scanning & policy:** Trivy/Checkov + pre-commit hooks to block secret strings; OPA policy denies `Secret` literals in manifests.

---

### 3) Affinity/anti-affinity for **mixed workloads** (compute-heavy + system services)

* **Label nodes:** `node=system`, `node=gpu`, `gpu.vendor=nvidia`, `topology.kubernetes.io/zone`.
* **Taints/tolerations:** taint GPU nodes `gpu=true:NoSchedule`; compute pods tolerate; system DaemonSets tolerate both.
* **Affinity patterns:**

  * System services (Fluent Bit, Node Exporter) → **DaemonSet** with tolerations for all nodes.
  * Heavy compute pods → `nodeAffinity` to `node=gpu`, `podAntiAffinity` on same `job-id` to spread.
  * Use **TopologySpreadConstraints** across zones to avoid AZ hotspots.

```yaml
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: node
            operator: In
            values: ["gpu"]
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector: { matchLabels: { app: trainer } }
          topologyKey: "kubernetes.io/hostname"
  topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: topology.kubernetes.io/zone
    whenUnsatisfiable: ScheduleAnyway
    labelSelector: { matchLabels: { app: trainer } }
```

---

### 4) **etcd backups** w/ petabyte-scale workloads (ensure zero control-plane data loss)

> Note: etcd holds **cluster state**, not PB app data. Goal = **zero RPO for control plane**, while app data uses its own replicated storage.

* **HA etcd** (3 or 5 members) on fast SSD; **encryption at rest**; regular `etcdctl defrag`.
* **Frequent snapshots:** `etcdctl snapshot save` every few minutes; store in versioned, encrypted object storage (S3) with **cross-region replication** and lifecycle.
* **Automate & test restore:** CronJob + integrity checks (`etcdctl snapshot status`), periodic full **disaster-recovery rehearsals**.
* **App data**: use replicated backends (EFS/FSx for Lustre, Portworx, Ceph/Rook) with **multi-AZ** replication & app-level checkpoints.

---

# Round 2 – Fire Drills, RCA & Chaos

### 1) Terraform plan wants to **recreate 100+ GPU nodes** (drift). Contain & roll forward

1. **Freeze changes & lock state.**
2. **Scope blast radius:** `terraform plan -target=module.node_group` and inspect replace reasons (launch template diff, tags, userdata).
3. **Reconcile vs. re-create:**

   * If infra is correct in cloud → `terraform import`/`moved` blocks/`ignore_changes` to align state.
   * If desired is correct → **batch Instance Refresh** per node group with small `maxUnavailable`, drain per batch.
4. **Protect critical pools:** `lifecycle { prevent_destroy = true }` on shared resources; use **workspaces** per env.
5. **Roll forward:** Apply to **canary node group**, soak, then promote waves. Keep previous AMI & template for immediate rollback.

---

### 2) **kube-proxy pods cycling**, workloads look healthy—what’s the hidden risk?

* kube-proxy programs **iptables/IPVS** rules. If it flaps, **new/updated Services/Endpoints won’t program**; existing connections may keep working (conntrack), hiding the issue until a **failover/rolling update** causes blackholes.
* **Actions:** confirm mode (`iptables` vs `ipvs`) → `ipvsadm -Ln` or `iptables -t nat -L`. Check API server reachability, version skew, CNI compatibility, node pressure. Fix root cause, then restart kube-proxy and verify rules.

---

### 3) **Container runtime** (e.g., containerd) crashloop on a node—replace without touching cluster

1. **Isolate:** `kubectl cordon <node>; kubectl drain <node> --ignore-daemonsets --delete-emptydir-data`.
2. **Triage on node:** `journalctl -u containerd -xe`, `crictl ps`, check disk (`/var/lib/containerd`), inode pressure, cgroups.
3. **Repair or replace:**

   * Quick fix: clear bad snapshot layers; restart runtime.
   * Safer: let **ASG/MNG** create a fresh node with the current launch template; terminate the bad node.
4. **Auto-remediation:** enable **Node Auto-Repair** (health checks) & Node Problem Detector.

---

### 4) **DNS misconfig** breaks service discovery on some nodes—live RCA + surgical fix

* **Detect:** Pods failing `*.svc` lookups; `kubectl exec ... -- nslookup kube-dns` fails.
* **Check core components:** `kubectl -n kube-system get pods -l k8s-app=kube-dns`; inspect CoreDNS logs for `SERVFAIL`/`refused`.
* **Node path:** verify **NodeLocal DNS** IP route (e.g., `169.254.20.10`), pod `/etc/resolv.conf` search domains, kubelet `--cluster-dns`.
* **Common fixes:**

  * Correct upstream resolvers in CoreDNS ConfigMap; `kubectl rollout restart deploy/coredns`.
  * Restore NodeLocalDNS DaemonSet or route rules.
  * If only some nodes: fix `/etc/resolv.conf` template or user-data, then **cordon/drain** and recycle affected nodes.

---

# Round 3 – Leadership, Scaling Mindset & Reliability Culture

### 1) Balance speed vs stability on **HPC-scale NVIDIA clusters**

* **SLOs & error budgets** drive release pace; if burned, we slow/stop risky changes.
* **Progressive delivery** (rings/waves, soak) + **feature flags** and **config toggles**.
* **Change policy:** two-person review, automated policy checks (OPA), prerelease load/canary tests that include NCCL + GPU utilization patterns.
* **Operations discipline:** freeze windows, rollback drills, immutable artifacts, golden AMIs, runbooks.

---

### 2) Cut infra costs by **20%** without reducing GPU capacity

* **Increase GPU utilization:** MIG on A/H-class GPUs, **bin-pack with scheduler extensions** (Volcano/Kueue), job preemption & backfill, right-size CPU\:GPU ratios and ephemeral storage.
* **Pricing levers:** Savings Plans/RIs for baseline, **Spot** for non-critical workers, regional pricing analysis.
* **Storage/network:** move cold data to S3-IA/Glacier; switch EBS to **gp3** w/ tuned IOPS; reduce cross-AZ traffic; compress & sample logs.
* **Platform waste:** turn off dev clusters off-hours, auto-scale system add-ons, slim images to cut pull time and EBS size.
* **Observability:** cost dashboards per **namespace/team/job**, showback/chargeback to drive behavior.

---

### 3) Post-incident process when **minutes = millions**

* **Immediate:** stabilize (rollback/feature flag), communicate ETA/status, protect customers first.
* **Within 24–48h:** blameless postmortem with precise timeline, customer impact quantified, **five whys**, and **decision log**.
* **Actions:** max 5–7 items, each with owner/ETA, tracked to closure; add **detectors** (SLO burn alerts, canary guards), **runbook updates**, test cases to prevent regressions.
* **Institutionalize:** make learnings part of policy (e.g., new guardrails, preflight checks), schedule **GameDays** to rehearse the class of failure.

---

## Handy snippets to reference live

**PDB for GPU jobs**

```yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata: { name: trainer-pdb }
spec:
  minAvailable: 90%
  selector: { matchLabels: { app: trainer } }
```

**ASG Instance Refresh (batchy)**

```bash
aws autoscaling start-instance-refresh \
  --auto-scaling-group-name gpu-ng-1 \
  --preferences MinHealthyPercentage=95,InstanceWarmup=600
```

**Drain with grace**

```bash
kubectl cordon $NODE
kubectl drain $NODE --ignore-daemonsets --delete-emptydir-data --grace-period=600 --timeout=30m
```


